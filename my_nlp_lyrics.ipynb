{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP project: lyric generation with LSTM model\n",
    "\n",
    "data from [kaggle](https://www.kaggle.com/mousehead/songlyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath = '/Users/weitinglin/Downloads/songdata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data = pd.read_csv(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for debugging\n",
    "sub_data = full_data[:100]\n",
    "tiny_data = full_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lyric_token(song):\n",
    "    '''\n",
    "    Add <eos> token (end of sentence)\n",
    "    Keep words with \"'\" combination (e.g. \"don't\")\n",
    "    '''\n",
    "    song = ' '.join([w for w in re.split('[^a-zA-Z]', song) if w])\n",
    "#     song = ''.join([w for w in song if w not in ['\\'','\\\"', ',', '-', '.', '!','?','(',')','[', ']',':']])\n",
    "    sentences = [s.strip().lower() + ' <eos>' for s in song.strip().split('\\n')]\n",
    "    lyric = []\n",
    "    for sentence in sentences:\n",
    "        lyric = lyric + [s.strip()  for s in sentence.strip().split(' ')]\n",
    "    return lyric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lyric_token(tiny_data['text'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### token to index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_vocab(text_list):\n",
    "    # make the dictionary\n",
    "    cnt = Counter()\n",
    "    for s in text_list:\n",
    "        token = lyric_token(s)\n",
    "        for t in token:\n",
    "            cnt[t] += 1\n",
    "\n",
    "    vocab = sorted(list(cnt.keys()))\n",
    "    print('total vocab:', len(vocab))\n",
    "    vocab_indices = dict((v, i) for i, v in enumerate(vocab))\n",
    "    indices_vocab = dict((i, v) for i, v in enumerate(vocab))\n",
    "    return cnt, vocab, vocab_indices, indices_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab: 485\n"
     ]
    }
   ],
   "source": [
    "_, vocab, vocab_indices, indices_vocab = make_vocab(tiny_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-46b4909a1afd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"heart\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# indices_vocab[50]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab_indices' is not defined"
     ]
    }
   ],
   "source": [
    "vocab_indices[\"heart\"]\n",
    "# indices_vocab[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization (and build x, y data for text generator)\n",
    "\n",
    "[ref.](https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lyric_token(song)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "primer_length = 10\n",
    "step_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_train_data(text_list, primer_len = 10, step = 3):\n",
    "    primers = []\n",
    "    next_words = []\n",
    "\n",
    "    # make primer-next_word pairs\n",
    "    for song in text_list:\n",
    "        # for each song\n",
    "        song_tokens = lyric_token(song)\n",
    "        for i in range(0, len(song_tokens) - primer_len, step):\n",
    "            # sliding window\n",
    "            primers.append(song_tokens[i: i + primer_len])\n",
    "            next_words.append(song_tokens[i + primer_len])\n",
    "    x = np.zeros((len(primers), primer_len, len(vocab)), dtype=np.bool)\n",
    "    y = np.zeros((len(primers), len(vocab)), dtype=np.bool)\n",
    "    for i, sentence in enumerate(primers):\n",
    "        for t, word in enumerate(sentence):\n",
    "            x[i, t, vocab_indices[word]] = 1\n",
    "        y[i, vocab_indices[next_words[i]]] = 1\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = make_train_data(tiny_data['text'], primer_len = primer_length, step = step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def primer_vec(p, primer_len):\n",
    "    '''\n",
    "    vectorize the primer\n",
    "    '''\n",
    "    sentence = lyric_token(p)[-primer_len:]\n",
    "    x = np.zeros((1, primer_len, len(vocab)), dtype=np.bool)\n",
    "    for t, word in enumerate(sentence):\n",
    "        if word in vocab_indices:\n",
    "            x[0, t, vocab_indices[word]] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM model with keras and train with tiny data \n",
    "[ref.](https://stackoverflow.com/questions/50090173/how-to-give-input-to-the-middle-layer-in-keras) about concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weitinglin/anaconda/envs/python3Env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Concatenate\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_a = 64 # number of hidden LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_a, input_shape=(primer_length, len(vocab))))\n",
    "model.add(Dense(len(vocab), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "873/873 [==============================] - 1s - loss: 5.9662     \n",
      "Epoch 2/3\n",
      "873/873 [==============================] - 0s - loss: 5.2167     \n",
      "Epoch 3/3\n",
      "873/873 [==============================] - 0s - loss: 5.0960     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123889470>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw(preds, temperature = 1.0):\n",
    "    '''\n",
    "    preds: the raw output from model\n",
    "    temperature: larger number means more random (equalized prob.)\n",
    "    '''\n",
    "    pred_exp = np.exp(np.log(preds)/ temperature)\n",
    "    prob = pred_exp / sum(pred_exp)\n",
    "    draw = choice(np.array(len(preds)), 1, p=prob)\n",
    "    return draw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw(model.predict(x[:1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make function to vectorize new examples\n",
    "# should handle new words\n",
    "\n",
    "def gen_next_word(my_primer_vec,  temperature = 1.0):\n",
    "    my_prob = model.predict(my_primer_vec)[0]\n",
    "    next_word = indices_vocab[draw(my_prob, temperature)]\n",
    "    return next_word\n",
    "# draw(my_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_primer1 = \"Look! It's a beautiful day, let's go hiking, shell we?\"\n",
    "my_primer_vec1 = primer_vec(my_primer1, primer_length)\n",
    "gen_next_word(primer_vec(my_primer1, primer_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make function to generate a song\n",
    "\n",
    "def gen_song(my_primer, primer_len, song_len,  temperature = 1.0):\n",
    "    my_primer_vec = primer_vec(my_primer, primer_len)\n",
    "    my_song = my_primer\n",
    "    for i in range(song_len - primer_len):\n",
    "        my_song += ' ' + gen_next_word(my_primer_vec, temperature)\n",
    "    \n",
    "    return my_song\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"And alone you must, alone you must, drink life's gull. 'cause Sorry Here around you Times ya I Tell wants\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_song(my_primer1, 10, 20, temperature = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train bigger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57650"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sub_data = full_data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab: 28143\n"
     ]
    }
   ],
   "source": [
    "# when would vacabulary saturate?\n",
    "for idx in [3000]:\n",
    "    cnt, vocab, vocab_indices, indices_vocab = make_vocab(full_data[:idx]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = sorted(cnt.items(), key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp[200:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab: 32886\n",
      "total example: 1100781\n"
     ]
    }
   ],
   "source": [
    "text_input = sub_data['text']\n",
    "primer_length = 8\n",
    "step_size = 2\n",
    "n_a = 32\n",
    "\n",
    "_, vocab, vocab_indices, indices_vocab = make_vocab(text_input)\n",
    "x, y = make_train_data(text_input, primer_len = primer_length, step = step_size)\n",
    "print(\"total example: {}\".format(y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 32)                4213632   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32886)             1085238   \n",
      "=================================================================\n",
      "Total params: 5,298,870\n",
      "Trainable params: 5,298,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_a, input_shape=(primer_length, len(vocab))))\n",
    "model.add(Dense(len(vocab), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14330/14330 [==============================] - 24s - loss: 6.0883    \n",
      "Epoch 2/10\n",
      "14330/14330 [==============================] - 25s - loss: 5.4018    \n",
      "Epoch 3/10\n",
      "14330/14330 [==============================] - 24s - loss: 4.9425    \n",
      "Epoch 4/10\n",
      "14330/14330 [==============================] - 23s - loss: 4.5497    \n",
      "Epoch 5/10\n",
      "14330/14330 [==============================] - 26s - loss: 4.1864    \n",
      "Epoch 6/10\n",
      "14330/14330 [==============================] - 32s - loss: 3.8409    \n",
      "Epoch 7/10\n",
      "14330/14330 [==============================] - 34s - loss: 3.5332    \n",
      "Epoch 8/10\n",
      "14330/14330 [==============================] - 30s - loss: 3.2637    \n",
      "Epoch 9/10\n",
      "14330/14330 [==============================] - 25s - loss: 3.0334    \n",
      "Epoch 10/10\n",
      "14330/14330 [==============================] - 27s - loss: 2.8267    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12504bb38>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_primer1 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I see a bird fly so high, and I think of you your We Gonna 'Cause I to, that I Don't Don't No your\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_song(my_primer1, primer_length, 20, temperature = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3Env]",
   "language": "python",
   "name": "conda-env-python3Env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
