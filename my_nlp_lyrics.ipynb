{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP project: lyric generation with LSTM model\n",
    "\n",
    "data from [kaggle](https://www.kaggle.com/mousehead/songlyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath = '/Users/weitinglin/Downloads/songdata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data = pd.read_csv(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debugging\n",
    "sub_data = full_data[:100]\n",
    "tiny_data = full_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lyric_token(song):\n",
    "    '''\n",
    "    Add <eos> token (end of sentence)\n",
    "    Keep words with \"'\" combination (e.g. \"don't\")\n",
    "    '''\n",
    "    song = ' '.join([w for w in re.split('[^a-zA-Z]', song) if w])\n",
    "#     song = ''.join([w for w in song if w not in ['\\'','\\\"', ',', '-', '.', '!','?','(',')','[', ']',':']])\n",
    "    sentences = [s.strip().lower() + ' <eos>' for s in song.strip().split('\\n')]\n",
    "    lyric = []\n",
    "    for sentence in sentences:\n",
    "        lyric = lyric + [s.strip()  for s in sentence.strip().split(' ')]\n",
    "    return lyric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lyric_token(tiny_data['text'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### token to index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_vocab(text_list, min_freq = 1):\n",
    "    '''\n",
    "    Make the dictionary\n",
    "    '''\n",
    "    cnt = Counter()\n",
    "    for s in text_list:\n",
    "        token = lyric_token(s)\n",
    "        for t in token:\n",
    "            cnt[t] += 1\n",
    "    \n",
    "\n",
    "    vocab = [v[0] for v in sorted(cnt.items(), key =lambda x: x[1]) if v[1] >= min_freq]\n",
    "    print('total vocab:', len(vocab))\n",
    "    vocab_indices = dict((v, i) for i, v in enumerate(vocab))\n",
    "    indices_vocab = dict((i, v) for i, v in enumerate(vocab))\n",
    "    return cnt, vocab, vocab_indices, indices_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-9219b6b3fb70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlyric_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a a b c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c63f4667248c>\u001b[0m in \u001b[0;36mlyric_token\u001b[0;34m(song)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mKeep\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0;34m\"'\"\u001b[0m \u001b[0mcombination\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m\"don't\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     '''\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^a-zA-Z]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#     song = ''.join([w for w in song if w not in ['\\'','\\\"', ',', '-', '.', '!','?','(',')','[', ']',':']])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' <eos>'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python3Env/lib/python3.5/re.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(pattern, string, maxsplit, flags)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     of the list.\"\"\"\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "lyric_token(['a a b c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab: 485\n"
     ]
    }
   ],
   "source": [
    "cnt, vocab, vocab_indices, indices_vocab = make_vocab(tiny_data['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab: 281\n"
     ]
    }
   ],
   "source": [
    "cnt, vocab, vocab_indices, indices_vocab = make_vocab(tiny_data['text'], min_freq=2)\n",
    "# temp[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_indices[\"love\"]\n",
    "# indices_vocab[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"lovers\" in vocab_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization (and build x, y data for text generator)\n",
    "\n",
    "[ref.](https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lyric_token(song)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "primer_length = 10\n",
    "step_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_train_data(text_list, primer_len = 10, step = 3):\n",
    "    primers = []\n",
    "    next_words = []\n",
    "\n",
    "    # make primer-next_word pairs\n",
    "    for song in text_list:\n",
    "        # for each song\n",
    "        song_tokens = lyric_token(song)\n",
    "        for i in range(0, len(song_tokens) - primer_len, step):\n",
    "            # sliding window\n",
    "            primers.append(song_tokens[i: i + primer_len])\n",
    "            next_words.append(song_tokens[i + primer_len])\n",
    "    # tokenization\n",
    "    x = np.zeros((len(primers), primer_len, len(vocab)), dtype=np.bool)\n",
    "    y = np.zeros((len(primers), len(vocab)), dtype=np.bool)\n",
    "    for i, sentence in enumerate(primers):\n",
    "        for t, word in enumerate(sentence):\n",
    "            if word in vocab:\n",
    "                x[i, t, vocab_indices[word]] = 1\n",
    "        if next_words[i] in vocab:\n",
    "            y[i, vocab_indices[next_words[i]]] = 1\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = make_train_data(tiny_data['text'], primer_len = primer_length, step = step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def primer_vec(p, primer_len):\n",
    "    '''\n",
    "    vectorize the primer\n",
    "    '''\n",
    "    sentence = lyric_token(p)[-primer_len:]\n",
    "    x = np.zeros((1, primer_len, len(vocab)), dtype=np.bool)\n",
    "    for t, word in enumerate(sentence):\n",
    "        if word in vocab_indices:\n",
    "            x[0, t, vocab_indices[word]] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM model with keras and train with tiny data \n",
    "[ref.](https://stackoverflow.com/questions/50090173/how-to-give-input-to-the-middle-layer-in-keras) about concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Concatenate\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_a = 64 # number of hidden LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_a, input_shape=(primer_length, len(vocab))))\n",
    "model.add(Dense(len(vocab), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "817/817 [==============================] - 1s - loss: 5.0127     \n",
      "Epoch 2/3\n",
      "817/817 [==============================] - 0s - loss: 4.4500     \n",
      "Epoch 3/3\n",
      "817/817 [==============================] - 0s - loss: 4.2636     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11c7f7c18>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw(preds, temperature = 1.0):\n",
    "    '''\n",
    "    preds: the raw output from model\n",
    "    temperature: larger number means more random (equalized prob.)\n",
    "    '''\n",
    "    pred_exp = np.exp(np.log(preds)/ temperature)\n",
    "    prob = pred_exp / sum(pred_exp)\n",
    "    draw = choice(np.array(len(preds)), 1, p=prob)\n",
    "    return draw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw(model.predict(x[:1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make function to vectorize new examples\n",
    "# should handle new words\n",
    "\n",
    "def gen_next_word(my_primer_vec,  temperature = 1.0):\n",
    "    my_prob = model.predict(my_primer_vec)[0]\n",
    "    next_word = indices_vocab[draw(my_prob, temperature)]\n",
    "    return next_word\n",
    "# draw(my_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_primer1 = \"Look! It's a beautiful day, let's go hiking, shell we?\"\n",
    "my_primer_vec1 = primer_vec(my_primer1, primer_length)\n",
    "gen_next_word(primer_vec(my_primer1, primer_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make function to generate a song\n",
    "\n",
    "def gen_song(my_primer, primer_len, song_len,  temperature = 1.0):\n",
    "    my_primer_vec = primer_vec(my_primer, primer_len)\n",
    "    my_song = my_primer\n",
    "    for i in range(song_len - primer_len):\n",
    "        my_song += ' ' + gen_next_word(my_primer_vec, temperature)\n",
    "    \n",
    "    return my_song\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Look! It's a beautiful day, let's go hiking, shell we? s slow burning feel sweet without see last saw it\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_song(my_primer1, 10, 20, temperature = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train bigger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57650"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sub_data = full_data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab: 9391\n"
     ]
    }
   ],
   "source": [
    "# when would vacabulary saturate?\n",
    "for idx in [3000]:\n",
    "    cnt, vocab, vocab_indices, indices_vocab = make_vocab(full_data[:idx]['text'], min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab: 2129\n",
      "total example: 13007\n"
     ]
    }
   ],
   "source": [
    "text_input = sub_data['text']\n",
    "primer_length = 8\n",
    "step_size = 2\n",
    "n_a = 32\n",
    "\n",
    "_, vocab, vocab_indices, indices_vocab = make_vocab(text_input)\n",
    "x, y = make_train_data(text_input, primer_len = primer_length, step = step_size)\n",
    "print(\"total example: {}\".format(y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 32)                276736    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2129)              70257     \n",
      "=================================================================\n",
      "Total params: 346,993\n",
      "Trainable params: 346,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_a, input_shape=(primer_length, len(vocab))))\n",
    "model.add(Dense(len(vocab), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13007/13007 [==============================] - 18s - loss: 6.0184    \n",
      "Epoch 2/10\n",
      "13007/13007 [==============================] - 16s - loss: 5.4106    \n",
      "Epoch 3/10\n",
      "13007/13007 [==============================] - 16s - loss: 4.9320    \n",
      "Epoch 4/10\n",
      "13007/13007 [==============================] - 16s - loss: 4.5170    \n",
      "Epoch 5/10\n",
      "13007/13007 [==============================] - 17s - loss: 4.1469    \n",
      "Epoch 6/10\n",
      "13007/13007 [==============================] - 16s - loss: 3.8203    \n",
      "Epoch 7/10\n",
      "13007/13007 [==============================] - 16s - loss: 3.5361    \n",
      "Epoch 8/10\n",
      "13007/13007 [==============================] - 16s - loss: 3.2801    \n",
      "Epoch 9/10\n",
      "13007/13007 [==============================] - 16s - loss: 3.0620    \n",
      "Epoch 10/10\n",
      "13007/13007 [==============================] - 16s - loss: 2.8709    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x100ddd1d0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_primer1 = \"Let me write a song for you, a lovely song <eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Let me write a song for you, a lovely song <eos> hang that here lovers every sometimes i know turn time keep help'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_song(my_primer1, primer_length, 20, temperature = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3Env]",
   "language": "python",
   "name": "conda-env-python3Env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
